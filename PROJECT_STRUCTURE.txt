AI_Judge/
├── README.md                       # Main documentation with architecture
├── QUICKSTART.md                   # 5-minute setup guide
├── PROJECT_SUMMARY.md              # Evaluation guide for reviewers
├── EVALUATION_CHECKLIST.md         # Verification checklist
├── sample_input.json               # Sample data for testing
├── .gitignore                      # Git ignore rules
├── start.sh                        # Convenience script to start both servers
│
├── backend/                        # FastAPI + SQLite Backend
│   ├── requirements.txt            # Python dependencies
│   ├── start.sh                    # Backend start script
│   ├── main.py                     # FastAPI app with all endpoints
│   ├── database.py                 # SQLite schema & connection
│   ├── models.py                   # Pydantic models for validation
│   ├── ollama_client.py            # Ollama LLM integration
│   └── ai_judge.db                 # SQLite database (created on first run)
│
└── frontend/                       # Vite + React 18 + TypeScript
    ├── package.json                # Node dependencies
    ├── tsconfig.json               # TypeScript configuration (strict mode)
    ├── tsconfig.node.json          # TypeScript config for Vite
    ├── vite.config.ts              # Vite configuration with proxy
    ├── index.html                  # HTML entry point
    ├── start.sh                    # Frontend start script
    │
    └── src/
        ├── main.tsx                # React entry point
        ├── App.tsx                 # Main app with routing
        ├── App.css                 # Global styles
        ├── types.ts                # TypeScript type definitions
        ├── api.ts                  # Type-safe API client
        │
        ├── components/             # Reusable components
        │   └── JudgeForm.tsx       # Judge create/edit form
        │
        └── pages/                  # Page components
            ├── UploadPage.tsx      # JSON file upload & ingestion
            ├── JudgesPage.tsx      # Judge CRUD management
            ├── AssignmentsPage.tsx # Judge-to-question assignments + Run
            └── ResultsPage.tsx     # Evaluation results with filters

DATABASE SCHEMA (SQLite):
═══════════════════════════════════════════════════════════════
submissions (id, queue_id, labeling_task_id, created_at, raw_data)
    │
    ├──> questions (id, submission_id, question_template_id, question_type, question_text, rev)
    │
    └──> answers (id, submission_id, question_template_id, choice, reasoning)

judges (id, name, system_prompt, model_name, active, created_at)
    │
    └──> judge_assignments (id, queue_id, question_template_id, judge_id, created_at)
         └──> evaluations (id, submission_id, question_template_id, judge_id, verdict, reasoning, created_at)

API ENDPOINTS:
═══════════════════════════════════════════════════════════════
Submissions:
  POST   /api/submissions/upload           - Upload JSON file
  GET    /api/queues                       - List queues
  GET    /api/queues/{id}/questions        - Get questions in queue

Judges:
  GET    /api/judges                       - List all judges
  POST   /api/judges                       - Create judge
  GET    /api/judges/{id}                  - Get judge
  PUT    /api/judges/{id}                  - Update judge
  DELETE /api/judges/{id}                  - Delete judge

Assignments:
  POST   /api/assignments                  - Assign judges to question

Evaluations:
  POST   /api/evaluations/run              - Run AI judges on queue
  GET    /api/evaluations                  - Get evaluations (with filters)
  GET    /api/evaluations/stats            - Get aggregate statistics

Ollama:
  GET    /api/ollama/models                - List available models

Health:
  GET    /health                           - Health check

USER FLOW:
═══════════════════════════════════════════════════════════════
1. Upload Data
   ↓ (sample_input.json → SQLite)
2. Create Judges
   ↓ (Define AI evaluators with prompts)
3. Assign Judges
   ↓ (Select which judges evaluate which questions)
4. Run Evaluations
   ↓ (Call Ollama for each question × judge pair)
5. View Results
   ↓ (Filter and analyze pass/fail statistics)

KEY FEATURES:
═══════════════════════════════════════════════════════════════
✅ Real Ollama LLM integration (not mocked)
✅ Persistent SQLite storage (not localStorage)
✅ Full TypeScript type safety (zero any)
✅ Comprehensive error handling
✅ Loading & empty states throughout
✅ Multi-judge support per question
✅ Advanced filtering (judge + question + verdict)
✅ Pass rate analytics
✅ Clean separation of concerns
✅ Idiomatic React patterns

TECH STACK:
═══════════════════════════════════════════════════════════════
Frontend:  Vite 5 + React 18 + TypeScript 5
Backend:   FastAPI + Python 3.8+
Database:  SQLite 3
LLM:       Ollama (local models)
Styling:   Custom CSS (no framework dependencies)

GETTING STARTED:
═══════════════════════════════════════════════════════════════
1. Install Ollama: https://ollama.ai
2. Pull model: ollama pull llama2
3. Start Ollama: ollama serve
4. Run app: ./start.sh
5. Open: http://localhost:5173

